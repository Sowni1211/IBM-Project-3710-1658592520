# -*- coding: utf-8 -*-
"""ass2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FctH27aW-IAU1rocansUD4N8v5dG8JWf
"""

import os
os.getcwd()

import numpy as np
import pandas as pd
import matplotlib.pyplot as pt

#importing the dataset
data_d = pd.read_csv("Churn_Modelling.csv")

data_d

#univariate analysis
data_d.info()

## here checking the data type of the variable

# Commented out IPython magic to ensure Python compatibility.
#for continous data type using scatter plot
import matplotlib.pyplot as pt
# %matplotlib inline

import seaborn as sns

pt.scatter(data_d.index,data_d['Balance'])
pt.show()

pt.scatter(data_d.index,data_d['EstimatedSalary'])
pt.show()

#bi variate analysis
#barplot
sns.barplot(x='Exited',y='EstimatedSalary',data=data_d)

#count plot
sns.countplot(x='Exited',data=data_d,hue='IsActiveMember')

#multivariate analysis
#pair plot
sns.pairplot(data=data_d)

#statitics
data_d.describe()

data_d.corr()

#missing valus
data_d.isna().sum()

#No Missing Values
#To find outlier we need to draw boxplot
sns.boxplot(x=data_d['CreditScore'])

#for credit score there are some outliers which are less than 400 values so we can drop the values that are less than 400 value in that particular column
#removed outliers
data_d.drop(data_d[(data_d['CreditScore'] <400)].index, inplace=True)

data_d.shape

sns.boxplot(x=data_d['Balance'])

sns.boxplot(x=data_d['EstimatedSalary'])

data_d.info()

#gepgraphy is categorical column and we can do label encoding
data_d['Geography']

from sklearn.preprocessing import LabelEncoder

L = LabelEncoder()

type(L)

data_d['encodinggeography'] = L.fit_transform(data_d['Geography'])

data_d['encodinggeography']

#gender column is also a categorical column
data_d['encodinggender'] = L.fit_transform(data_d['Gender'])

data_d['encodinggender']

data_d.iloc[:,[4,-2,5,-1]]

#splitting into dependent and independent
data_d.drop(['Geography','Gender'],axis=1)

y = data_d['Exited']

x = data_d.drop(['Gender','Geography','Exited'],axis=1)

#standardscaling the independent vaiable of the dataset
from sklearn.preprocessing import StandardScaler

st = StandardScaler()

x = x.drop(['Surname'],axis=1)

x = st.fit_transform(x)

x



#splitting the dataset into training and testing



from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2)

xtrain

ytrain

ytest

xtest